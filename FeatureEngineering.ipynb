{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LtgDNh2vP8N"
      },
      "source": [
        "# Estimador de precios de inmuebles en la ciudad de San Juan, Argentina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gDU9Cn19JYu"
      },
      "source": [
        "## 1. Inicialización: librerías, configuraciones y variables globales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqBHioMDvbTo"
      },
      "source": [
        "### Importación de Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "90ZJqL-PbBM5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import re\n",
        "import unicodedata\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AflmSPa2vhjk"
      },
      "source": [
        "## 2. Importación de Base de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkAOTvco0BUT"
      },
      "source": [
        "### Buscar la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGdFIHB20fZ6"
      },
      "outputs": [],
      "source": [
        "\n",
        "db_path_colab = 'inmuebles_sanjuan.db'\n",
        "\n",
        "if os.path.exists(db_path_colab):\n",
        "  db_exists = True\n",
        "else:\n",
        "  db_exists = False\n",
        "\n",
        "conn = sqlite3.connect('inmuebles_sanjuan.db')\n",
        "df_all = pd.read_sql_query(\"SELECT * FROM inmuebles\", conn)\n",
        "conn.close()\n",
        "\n",
        "df_all.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8lXMME894nE"
      },
      "source": [
        "## 3. Parseamos las caracteristicas contenidas en el html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0anYLrw8z4IP"
      },
      "outputs": [],
      "source": [
        "def parse_caracteristicas(html):\n",
        "    if html is None:\n",
        "        return {}\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    caracteristicas = {}\n",
        "    for p in soup.find_all('p', class_='name-caracteristica'):\n",
        "      try:\n",
        "        # Extract the characteristic name (before the colon)\n",
        "        characteristic_name = p.text.split(':')[0].strip()\n",
        "        # Extract the characteristic value (within the span)\n",
        "        characteristic_value = p.find('span').text.strip()\n",
        "        caracteristicas[characteristic_name] = characteristic_value\n",
        "      except:\n",
        "        pass\n",
        "    return caracteristicas\n",
        "\n",
        "# Apply the function to the 'html' column\n",
        "df_all['caracteristicas'] = df_all['html'].apply(parse_caracteristicas)\n",
        "\n",
        "# Expand the dictionary into separate columns\n",
        "df_all = pd.concat([df_all, pd.json_normalize(df_all['caracteristicas'])], axis=1)\n",
        "\n",
        "\n",
        "df_all.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Agregamos la Longitud y Latitud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def extract_lat_long(html):\n",
        "    \"\"\"\n",
        "        Extrae la latitud y longitud de un string HTML que contiene el siguiente formato:\n",
        "        L.marker([-31.538911593868313, -68.49121665865825],\n",
        "    \"\"\"\n",
        "    if html is None:\n",
        "        return None, None\n",
        "    # Regex pattern to match the latitude and longitude\n",
        "    \n",
        "    pattern = r\"L\\.marker\\(\\[(-?\\d+\\.\\d+),\\s*(-?\\d+\\.\\d+)\\]\"\n",
        "    match = re.search(pattern, html)\n",
        "    if match:\n",
        "        latitude = float(match.group(1))\n",
        "        longitude = float(match.group(2))\n",
        "        return latitude, longitude\n",
        "    return None, None\n",
        "\n",
        "# Apply the function to the 'html' column\n",
        "df_all[['Latitude', 'Longitude']] = df_all['html'].apply(lambda x: pd.Series(extract_lat_long(x)))\n",
        "\n",
        "df_all.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Extraemos la descripción del anuncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QWQmyyA1JLN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_comentario_caracteristicas(html):\n",
        "    if html is None:\n",
        "      return \"\"\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    comentario_element = soup.find('p', class_='comentario-caracteristicas-anuncio')\n",
        "    if comentario_element:\n",
        "      return comentario_element.text.strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "df_all['Comentario Caracteristicas'] = df_all['html'].apply(extract_comentario_caracteristicas)\n",
        "\n",
        "df_all.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_image_as_blob(url_imagen):\n",
        "    full_url = 'https://www.compraensanjuan.com/' + url_imagen\n",
        "    try:\n",
        "        response = requests.get(full_url)\n",
        "        response.raise_for_status()\n",
        "        return response.content  # Return the image as binary data (blob)\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching image from {full_url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Apply the function to the 'url_imagen' column and store the blob in a new column\n",
        "df_all['image_blob'] = df_all['url_imagen'].apply(fetch_image_as_blob)\n",
        "\n",
        "df_all.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Borramos las columnas que no nos hacen falta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Borramos las columnas que no nos interesan\n",
        "df_all = df_all.drop(columns=['html', 'url', 'url_imagen', 'caracteristicas'])\n",
        "df_all.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Seteamos datos en null cuando está el texto \"Sin especificar\", texto vacío y nan. También arreglamos los nombres de las columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_all = df_all.replace({'Sin especificar': None})\n",
        "df_all = df_all.replace({'': None})\n",
        "df_all = df_all.replace({'nan': None})\n",
        "# Eliminamos los caracteres especiales de las columnas\n",
        "df_all.columns = df_all.columns.str.replace(' ', '_')\n",
        "df_all.columns = df_all.columns.str.replace('(', '')\n",
        "df_all.columns = df_all.columns.str.replace(')', '')\n",
        "df_all.columns = df_all.columns.str.replace('/', '_')\n",
        "df_all.columns = df_all.columns.str.replace('-', '_')\n",
        "df_all.columns = df_all.columns.str.replace('?', '')\n",
        "df_all.columns = df_all.columns.str.replace('!', '')\n",
        "\n",
        "df_all.columns = df_all.columns.str.lower()\n",
        "\n",
        "def remove_diacritics(input_str):\n",
        "\t\"\"\"\n",
        "\tRemoves diacritics from the input string.\n",
        "\t\"\"\"\n",
        "\treturn ''.join(\n",
        "\t\tc for c in unicodedata.normalize('NFD', input_str)\n",
        "\t\tif unicodedata.category(c) != 'Mn'\n",
        "\t)\n",
        "\n",
        "\n",
        "df_all.columns = [remove_diacritics(col) for col in df_all.columns]\n",
        "\n",
        "df_all.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. Guardamos la base de datos final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the DataFrame to a new SQLite database\n",
        "conn_full = sqlite3.connect('inmuebles_full.db')\n",
        "df_all.to_sql('inmuebles', conn_full, if_exists='replace', index=False)\n",
        "conn_full.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
