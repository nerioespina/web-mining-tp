{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LtgDNh2vP8N"
      },
      "source": [
        "# Estimador de precios de inmuebles en la ciudad de San Juan, Argentina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gDU9Cn19JYu"
      },
      "source": [
        "## 1. Inicialización: librerías, configuraciones y variables globales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqBHioMDvbTo"
      },
      "source": [
        "### Importación de Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "90ZJqL-PbBM5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkAOTvco0BUT"
      },
      "source": [
        "### Buscar la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGdFIHB20fZ6"
      },
      "outputs": [],
      "source": [
        "\n",
        "db_path_colab = 'inmuebles_sanjuan_venta_con_precio.db'\n",
        "\n",
        "if os.path.exists(db_path_colab):\n",
        "  db_exists = True\n",
        "else:\n",
        "  db_exists = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AflmSPa2vhjk"
      },
      "source": [
        "## 2. Importación de datos base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgeakcfDshCq"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_data = []\n",
        "\n",
        "if not db_exists:\n",
        "    # Iterar sobre las páginas\n",
        "    for page in range(1, 277):  # Ajusta el rango según el número de páginas disponibles\n",
        "        try:\n",
        "            page_url = f\"https://www.compraensanjuan.com/b_in.php?tipo=0&operacion=03&zona=0&dormitorios=Todos&aptocredito=Todos&barrioprivado=Todos&vendedor=Todos&precio_desde=&precio_hasta=&pagina={page}&orden=0&conprecio=true&estado=&foto=\"\n",
        "\n",
        "            # Realizar la solicitud GET\n",
        "            response = requests.get(page_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "            response.raise_for_status()  # Verificar si la solicitud fue exitosa\n",
        "\n",
        "            # Analizar el contenido HTML\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            divs = soup.find_all('div', class_='lista-avisos')\n",
        "\n",
        "            # Extraer los datos de cada aviso\n",
        "            for div in divs:\n",
        "                link_url = None\n",
        "                img_url = None\n",
        "                aviso_title = None\n",
        "                precio = None\n",
        "                publicacion = None\n",
        "                visitas = None\n",
        "\n",
        "                link_element = div.find('a', class_='title orange-link')\n",
        "                if link_element:\n",
        "                    link_url = link_element['href']\n",
        "\n",
        "                img_element = div.find('img', class_='img-lista')\n",
        "                if img_element:\n",
        "                    img_url = img_element['src']\n",
        "\n",
        "                aviso_title_element = div.find('p', class_='aviso-title')\n",
        "                if aviso_title_element:\n",
        "                    aviso_title = aviso_title_element.text.strip()\n",
        "\n",
        "                precio_element = div.find('p', class_='precio')\n",
        "                if precio_element:\n",
        "                    precio = precio_element.text.strip()\n",
        "\n",
        "                publicacion_element = div.find('p', class_='publicacion')\n",
        "                if publicacion_element:\n",
        "                    publicacion = publicacion_element.text.strip()\n",
        "\n",
        "                visitas_element = div.find('p', class_='visitas')\n",
        "                if visitas_element:\n",
        "                    visitas = visitas_element.text.strip()\n",
        "                \n",
        "                categoria = div.find_all('a', class_='categoria')[1]\n",
        "                if categoria:\n",
        "                    categoria = categoria.text.strip()\n",
        "                else:\n",
        "                    categoria = None\n",
        "\n",
        "                all_data.append([link_url, img_url, aviso_title, precio, publicacion, visitas, categoria])\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching page {page}: {e}\")\n",
        "            continue  # Continuar con la siguiente página en caso de error\n",
        "\n",
        "    # Crear un DataFrame con todos los datos\n",
        "    df_all = pd.DataFrame(all_data, columns=['url', 'url_imagen', 'titulo', 'precio', 'publicacion', 'visitas', 'categoria'])\n",
        "    df_all['html'] = None\n",
        "    df_all['procesado'] = False\n",
        "    df_all['anuncio_id'] = df_all['url'].str.extract(r'anuncio_in/(\\d+)/')\n",
        "    \n",
        "    # Connect to SQLite database\n",
        "    conn = sqlite3.connect(db_path_colab)\n",
        "    # Create a cursor object\n",
        "    cursor = conn.cursor()\n",
        "    # Create a table if it doesn't exist\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS inmuebles (\n",
        "            url         text,\n",
        "            url_imagen  text,\n",
        "            titulo      text,\n",
        "            precio      text,\n",
        "            publicacion text,\n",
        "            visitas     text,\n",
        "            categoria   text,\n",
        "            html        text,\n",
        "            procesado   boolean default false,\n",
        "            anuncio_id  integer primary key\n",
        "        );\n",
        "    ''')\n",
        "\n",
        "    # Insert the data from the DataFrame into the table\n",
        "    df_all.to_sql('inmuebles', conn, if_exists='replace', index=False)\n",
        "    # Commit the changes\n",
        "    conn.commit()\n",
        "    # Close the connection\n",
        "    conn.close()\n",
        "else:\n",
        "    conn = sqlite3.connect('inmuebles_sanjuan_venta_con_precio.db')\n",
        "    df_all = pd.read_sql_query(\"SELECT * FROM inmuebles\", conn)\n",
        "    conn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td5je6QN53r_"
      },
      "source": [
        "## 3. Extraemos la información de cada publicación:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos la función get_html_from_url que nos permitirá traer el html de cada detalle del inmueble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_html_from_url(url):\n",
        "  try:\n",
        "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    response.raise_for_status()\n",
        "    return response.content\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching URL: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conectar a la base de datos SQLite\n",
        "conn = sqlite3.connect('inmuebles_sanjuan_venta_con_precio.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "while True:\n",
        "    # Buscar el primer registro que tenga html null\n",
        "    cursor.execute(\"SELECT * FROM inmuebles WHERE html IS NULL LIMIT 1\")\n",
        "    record = cursor.fetchone()\n",
        "\n",
        "    if not record:\n",
        "        print(\"No se encontraron más registros con html null\")\n",
        "        break\n",
        "\n",
        "    url = record[0]  # Asumiendo que la URL está en la primera columna\n",
        "    full_url = 'https://www.compraensanjuan.com/' + url\n",
        "    html_content = get_html_from_url(full_url)\n",
        "\n",
        "    if html_content:\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "        html_str = str(soup)\n",
        "\n",
        "        # Actualizar el registro con el HTML extraído\n",
        "        cursor.execute(\"UPDATE inmuebles SET html = ? WHERE url = ?\", (html_str, url))\n",
        "        conn.commit()\n",
        "        print(f\"HTML extraído y actualizado para el registro con URL: {url}\")\n",
        "    else:\n",
        "        print(f\"No se pudo extraer el HTML para la URL: {url}\")\n",
        "\n",
        "# Cerrar la conexión\n",
        "conn.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
